{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas help\n",
    "#https://pandas.pydata.org/Pandas_Cheat_Sheet.pdfhttps://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "#http://datacamp-community-prod.s3.amazonaws.com/dbed353d-2757-4617-8206-8767ab379ab3\n",
    "\n",
    "\n",
    "#reading the datafrom using pandas\n",
    "df=pd.read_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature scalling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "#min max scalling\n",
    "from sklearn.preprocessing import MinMaxScaler()\n",
    "ms=MinMaxScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1] finding the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas \n",
    "df.isnull().sum()\n",
    "\n",
    "# null if follow certain condition\n",
    "print((dataset[[1,2,3,4,5]] == 0).sum())\n",
    "\n",
    "***********************************************************************************************************\n",
    "#using missingo to visulazise\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import missingno as msno\n",
    "no_of_datapoint=1000\n",
    "\n",
    "#in matrix formate\n",
    "msno.matrix(collisions.sample(no_of_datpoint))\n",
    "\n",
    "#in bargraph formate\n",
    "msno.bar(df.sample(no_of_datapoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] handling missing values (simple stratagies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erasing all columns with missing value\n",
    "df.dropna(inplace=True,axis='columns')\n",
    "\n",
    "#replacing NaN with certain value\n",
    "replacing_value=999\n",
    "df = dfreplace( numpy.NaN,replacing_value)\n",
    "\n",
    "# erasing the column with missing value \n",
    "#for row no need to specify column_name and axis\n",
    "df.drop('column_name', axis=1, inplace=True)\n",
    "\n",
    "********************************************************************************************************************\n",
    "#for specific column **specify column in bracket\n",
    "df.fillna(df.mean()['B':'C'])\n",
    "\n",
    "# fill missing values with mean column values\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "\n",
    "#replacing with mean or median or most frequent\n",
    "from sklearn.preprocessing import Imputer\n",
    "values = df.values\n",
    "imputer = Imputer(missing_values=’NaN’, strategy=’mean’)\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "# strategy can be changed to \"median\" and “most_frequent”\n",
    "\n",
    "\n",
    "********************************************************************************************************************\n",
    "#for time series data\n",
    "#ts is time series data\n",
    "\n",
    "#fill the value forward to missing value limit show maximum no of continuos value to replace\n",
    "ts.fillna(method='pad', limit=1)\n",
    "\n",
    "#fill the value backward to missing value limit show maximum no of continuos value to replace\n",
    "ts.fillna(method='bfill', limit=1)\n",
    "\n",
    "#inteplotation method\n",
    "#***method:{time,values,barycentric,pchip,akima}\n",
    "ts.interpolate(method='time')\n",
    "\n",
    "\n",
    "##When interpolating via a polynomial or spline approximation, \n",
    "##you must also specify the degree or order of the approximation:\n",
    "#***method:{spline,polynomial}\n",
    "ts.interpolate(method='spline', order=2)\n",
    "*******************************************************************************************************************\n",
    "#for more help\n",
    "##https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # finding the categorical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the datatype\n",
    "df.dtypes\n",
    "print(df_flights.info())\n",
    "\n",
    "########################################\n",
    "#copyig the categorical data \n",
    "import copy\n",
    "cat_df = df.select_dtypes(include=['object']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tip: in Python, it's a good practice to typecast categorical features to a category dtype because they make the operations on such columns much faster than the object dtype. You can do the typecasting by using .astype() method on your columns like shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handling categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the category with the required number\n",
    "replace_map = {'carrier': {'AA': 1, 'AS': 2, 'B6': 3, 'DL': 4,\n",
    "                                  'F9': 5, 'HA': 6, 'OO': 7 , 'UA': 8 , 'US': 9,'VX': 10,'WN': 11}}\n",
    "cat_df_replace.replace(replace_map_comp, inplace=True)\n",
    "\n",
    "#to get replace map automatically for large dataset\n",
    "labels = cat_df_flights['carrier'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'carrier' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "\n",
    "#you can use np.where for binary category feature\n",
    "df[\"column\"]=np.where(df[\"columns\"].str.contains(\"category\"),1,0)\n",
    "\n",
    "#################################################################################################################\n",
    "#using sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "#for single column\n",
    "df[\"column\"]=lb_make.fit_transform(df[\"column\"])\n",
    "#for multiple columns \n",
    "df=df.apply(lb_make.fit_transform)# WARNING: df should include only categorical data \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe using get_dummies() \n",
    "dummies = data[\"columns\"].str.get_dummies(\" \") \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oe=OneHotEncoder()\n",
    "df[\"column\"]=oe.fit_transform(df[\"column\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handling both categorical and numerical data simulataneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_selector #make selector use to selectt the columns with certain dtype\n",
    "ct = ColumnTransformer([\n",
    "       ('scale', StandardScaler(),\n",
    "       make_column_selector(dtype_include=np.number)),# scale and onehot referece to column name\n",
    "       ('onehot',\n",
    "       OneHotEncoder(),\n",
    "       make_column_selector(pattern='city', dtype_include=object))]\n",
    "       ,remainder=MinMaxScaler()) #remainder is use to appply with remaining features\n",
    "\n",
    "column_trans.fit(X)\n",
    "\n",
    "column_trans.get_feature_names()\n",
    "\n",
    "\n",
    "#to automaticlly give the name to the generated features\n",
    "from sklearn.compose import make_column_transformer\n",
    "# use make_column_transformer instead of columnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
